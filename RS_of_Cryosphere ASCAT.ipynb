{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f05de45-f623-4a9b-8bcf-b2f69d82f408",
   "metadata": {},
   "source": [
    "# 3. ASCAT application\n",
    "## Estimating the melt areas and last day of melt in Antarctic Peninsula using ASCAT data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf49b8-3a97-46ba-9cda-91cb19c5aea5",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Surface melt on the Antarctic Ice Sheet is a critical component of sea level rise projections, with estimates varying widely due to uncertainties surrounding the future of Antarctic ice shelves. \n",
    "While enhanced basal melt and iceberg calving currently dominate ice mass loss, surface melt, though playing a marginal role, can indirectly contribute by destabilizing ice shelves. Recent climate models predict a doubling of Antarctic surface melt by 2050, driven by atmospheric warming, potentially leading to significant increases in sea level rise contribution. Monitoring surface melt is essential for understanding these dynamics and refining projections.\n",
    "\n",
    "Currently, three methods are utilized to estimate surface melt: automatic weather stations (AWSs), physics-based (regional) climate models (RCMs), and remote sensing. AWS observations facilitate the computation of surface energy balance and the estimation of excess energy available for surface melt. Initially, studies relied on temperature data from AWSs dating back to 1947, with subsequent research utilizing more advanced AWSs equipped with radiation sensors. While AWS observations are often considered \"ground truth,\" their limitation lies in being point-based and restricted to a limited number of locations, thus inadequate for continentwide melt studies. Additionally, AWS locations are biased toward homogeneous snow surfaces, overlooking more complex surface types like blue ice, slush, and other wet surfaces.\n",
    "\n",
    "The second method employs RCMs to estimate surface melt on a continental scale. However, the accuracy of RCMs depends on the resolution and precision of the forcing data, which often fall short for the Antarctic Ice Sheet. Furthermore, RCMs struggle to capture detailed melt features over low albedo regions due to their limited resolution.\n",
    "\n",
    "Remote sensing provides an alternative for deriving long-term melt dynamics, offering various spatiotemporal resolutions. Various sensors, including radiometers, scatterometers, synthetic aperture radar, and optical sensors, enable the detection of wet surface conditions such as wet snow, slush, melt ponds, and streams. These sensors provide data for assessing the spatial and temporal patterns of surface melt, offering insights into its duration and distribution across the continent. \n",
    "Satellites equipped with remote sensing technology offer insights into the Antarctic surface across a broad spectrum of electromagnetic wavelengths, ranging from visible light to microwaves. These sensors detect surface reflectance, backscatter intensity (Ïƒ0), and brightness temperature (Tb). Changes in these parameters indicate the presence of liquid water, serving as indicators for its presence rather than directly observing the physical process of surface melt. Surface melt is essentially an energy conversion process, although thermal-infrared-derived surface temperature can pinpoint its occurrence at the melting point. Despite this distinction, the term \"surface melt\" is commonly used in remote sensing discourse. However, sensors primarily detect the presence of liquid water.\n",
    "Furthermore, observations of backscatter intensity, brightness temperature, and surface reflectance are influenced by sensor characteristics and surface properties. Consequently, significant disparities can arise in surface melt estimates derived from different sensors, highlighting the importance of considering these factors when interpreting remote sensing data.\n",
    "By exploiting satellite technology, researchers can enhance our understanding of Antarctic surface melt dynamics and their implications for future sea level rise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aadd1d-35c9-4582-be58-06dbc12b10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio pyproj pandas cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8a2c0-6e34-426f-8148-7ce2f39ce9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from pyproj import Proj, transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84bb93a-3aae-4487-8e76-7dd5fa79cbb5",
   "metadata": {},
   "source": [
    "## ASCAT data\n",
    "ASCAT operates in C-band [5.255 GHz] and antennas are vertically-polarized only. In the southern hemisphere, ASCAT passes in the morning and in the evening. The 4.45 km enhanced resolution product is used, which was developed by the NASA Scatterometer Climate Record Pathfinder Project (available at: \\url{http://www.scp.byu.edu}, last accessed on 24 May 2023). The TIFF files you are going to use have been downloaded using the Google Earth Engine tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaefe51-deaa-4a13-8804-efc590b5c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the georeferenced TIFF file\n",
    "file_path = \"Data/ASCAT/ascat_stack.tif\"\n",
    "\n",
    "# Open the TIFF file using rasterio\n",
    "with rasterio.open(file_path) as src:\n",
    "    # Display basic information about the file\n",
    "    print(\"Number of bands:\", src.count)\n",
    "    print(\"Matrix dimensions:\", src.shape)\n",
    "    print(\"Spatial reference system:\", src.crs)\n",
    "    print(\"Geographic extent:\", src.bounds)\n",
    "    \n",
    "    # Display the TIFF file\n",
    "    show(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57384d91-0b7d-46b6-bc33-148886ff3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of parameters\n",
    "left, bottom, right, top = -2856900.0, 418300.0, -1441800.0, 1637600.0\n",
    "rows, cols = 274, 318\n",
    "resolution = 4450  # Step\n",
    "\n",
    "# Creation of meshgrid matrices for x and y coordinates\n",
    "x = np.linspace(left, right, cols)\n",
    "y = np.linspace(bottom, top, rows)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "# Conversion of x and y coordinates to longitude and latitude (EPSG:3031)\n",
    "in_proj = Proj(init='epsg:3031')\n",
    "out_proj = Proj(proj='latlong', datum='WGS84')\n",
    "lon, lat = transform(in_proj, out_proj, xx, yy)\n",
    "\n",
    "# Path to the georeferenced TIFF file\n",
    "file_path = \"Data/ASCAT/ascat_stack.tif\"\n",
    "\n",
    "# Open the TIFF file using rasterio\n",
    "with rasterio.open(file_path) as src:\n",
    "    # Peninsula mask\n",
    "    flipped = src.read(1)\n",
    "    mask = np.where(np.isnan(flipped), np.nan, 1)\n",
    "    # Plot of the src using latitude and longitude coordinates\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.imshow(src.read(1), cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()))\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title('Georeferenced TIFF Image')\n",
    "    plt.colorbar(label='Pixel Value')\n",
    "    plt.grid(visible=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad230a83-a26b-41b4-8016-b1c05c2ae1a1",
   "metadata": {},
   "source": [
    "## Importing dates\n",
    "\n",
    "Dates (one for each image) are stored in a separate .csv file. They have to be imported and converted in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e58a31-ad42-4754-ba98-78a8f0e6a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load CSV file\n",
    "csv_file = \"Data/ASCAT/ascat_date.csv\"\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Extract dates column\n",
    "dates_column = data['dates']\n",
    "\n",
    "# Split each string in the Series by commas to get individual date strings\n",
    "date_strings = dates_column.apply(lambda x: x.split(','))\n",
    "\n",
    "# Flatten the list of lists to get a single list of date strings\n",
    "date_strings_flat = [date for sublist in date_strings for date in sublist]\n",
    "\n",
    "# Convert each string date to a datetime object and store them in a list\n",
    "dates = [datetime.strptime(date, '%Y-%m-%d').date() for date in date_strings_flat]\n",
    "\n",
    "\n",
    "# Print the first few dates as a sample\n",
    "print(\"Sample of dates extracted from CSV:\")\n",
    "for date in dates[:5]:\n",
    "    print(date)\n",
    "\n",
    "# Now 'dates' list contains all the dates from the CSV file as datetime objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df8f04-0a01-4e2e-8d9e-35fa17844f66",
   "metadata": {},
   "source": [
    "## ASCAT images stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c57374-b425-411b-8b17-ba1864be85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the TIFF file using rasterio\n",
    "with rasterio.open(file_path) as src:\n",
    "    # Read all bands into a single numpy array stack\n",
    "    stack_ascat = src.read()\n",
    "\n",
    "# Check the shape of the stack\n",
    "print(\"Shape of stack_ascat:\", stack_ascat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9f79d-a872-49b5-8b9e-501912f0f3b3",
   "metadata": {},
   "source": [
    "## Annual stack \n",
    "Antarctic yearly stack: we are analyzing Antarctica, so we are going to create a annual stack with a 6-month offset. \n",
    "Now we will see how to create sub-stacks using defined dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873355d-4771-4a1b-916e-c68835ed62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_indices_between_dates(dates, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Find the indices of dates in the dates array between start_date and end_date.\n",
    "\n",
    "    Args:\n",
    "        dates (numpy.ndarray): Array of dates.\n",
    "        start_date (numpy.datetime64): Start date.\n",
    "        end_date (numpy.datetime64): End date.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array of indices of dates between start_date and end_date.\n",
    "    \"\"\"\n",
    "    indices = np.where((dates >= start_date) & (dates <= end_date))[0]\n",
    "    return indices\n",
    "\n",
    "# 2018-19\n",
    "start_date = np.datetime64(\"2018-06-01\")\n",
    "end_date = np.datetime64(\"2019-06-30\")\n",
    "indices_1819 = find_indices_between_dates(dates, start_date, end_date)\n",
    "stack_1819 = stack_ascat[indices_1819]\n",
    "\n",
    "# 2019-20\n",
    "start_date = np.datetime64(\"2019-06-01\")\n",
    "end_date = np.datetime64(\"2020-06-30\")\n",
    "indices_1920 = find_indices_between_dates(dates, start_date, end_date)\n",
    "stack_1920 = stack_ascat[indices_1920]\n",
    "\n",
    "# 2020-21\n",
    "start_date = np.datetime64(\"2020-06-01\")\n",
    "end_date = np.datetime64(\"2021-06-30\")\n",
    "indices_2021 = find_indices_between_dates(dates, start_date, end_date)\n",
    "stack_2021 = stack_ascat[indices_2021]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765733e-435d-49a1-bbd5-62c22b120b7d",
   "metadata": {},
   "source": [
    "## Stack reprojection\n",
    "\n",
    "EPSG (European Petroleum Survey Group) codes are a standard way to reference coordinate systems and projections. In Antarctica, EPSG reprojections are commonly used to transform spatial data from one coordinate reference system to another. This is crucial for various applications such as mapping, geospatial analysis, and satellite imagery interpretation.\n",
    "\n",
    "The most common EPSG code used in Antarctica is EPSG:3031, which represents the Antarctic Polar Stereographic projection. This projection is specifically designed for the polar regions and is optimized for accurate representation of areas near the poles. Here's how it works:\n",
    "\n",
    "1. **Projection**: The Antarctic Polar Stereographic projection projects the spherical surface of the Earth onto a two-dimensional plane. It uses a stereographic projection method, which means that lines of longitude are projected as straight lines radiating from a point at the center of the projection, while lines of latitude are projected as concentric circles centered on that point.\n",
    "\n",
    "2. **Datum**: The EPSG:3031 projection typically uses the WGS 84 datum, which is a global geodetic datum widely used in GPS systems and mapping applications. The WGS 84 datum defines the shape and size of the Earth's ellipsoid and serves as a reference for geospatial data.\n",
    "\n",
    "3. **Parameters**: The EPSG:3031 projection has specific parameters that define how the projection is applied, such as the central meridian and the latitude of true scale. In the case of EPSG:3031, the central meridian is set to 0 degrees, and the latitude of true scale is set to -71 degrees (for the southern hemisphere).\n",
    "\n",
    "4. **Transformation**: When data in a different coordinate reference system (CRS) needs to be displayed or analyzed alongside data in EPSG:3031, a reprojection is performed. This involves transforming the coordinates of each point in the original CRS to their equivalent coordinates in EPSG:3031. This transformation takes into account the mathematical formulas and parameters of the specific projections involved.\n",
    "\n",
    "EPSG reprojections in Antarctica, particularly using EPSG:3031, enable accurate representation and analysis of spatial data in a way that is optimized for the unique characteristics of the polar region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c795f5-a7a6-4d2d-b8d6-56c091e8d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot yearly stacks\n",
    "# Let's proceed with calculating the average of these stacks and plotting them in the selected projection.\n",
    "\n",
    "# Assuming stack_1819, stack_1920, and stack_2021 are numpy arrays containing the stacked images\n",
    "# Let's calculate the mean of each stack\n",
    "mean_stack_1819 = np.nanmean(stack_1819, axis=0)\n",
    "mean_stack_1920 = np.nanmean(stack_1920, axis=0)\n",
    "mean_stack_2021 = np.nanmean(stack_2021, axis=0)\n",
    "\n",
    "# Plot the georeferenced mean stacks\n",
    "plt.figure(figsize=(12, 2))\n",
    "\n",
    "# Plot mean_stack_1819\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(mean_stack_1819,  cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=1)\n",
    "plt.title(\"Mean Stack 2018-2019\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)  # Adjust colorbar font size\n",
    "\n",
    "# Plot mean_stack_1920\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mean_stack_1920,  cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=1)\n",
    "plt.title(\"Mean Stack 2019-2020\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)  # Adjust colorbar font size\n",
    "\n",
    "# Plot mean_stack_2021\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(mean_stack_2021,  cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=1)\n",
    "plt.title(\"Mean Stack 2020-2021\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)  # Adjust colorbar font size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81935ad-492b-4d1c-92a0-4e01eef3fe29",
   "metadata": {},
   "source": [
    "## New stack creation based on winter season\n",
    "\n",
    "Let's generate new stacks covering the period from June 1st to August 31st, known as the winter season.  These stacks are essential because the detection of melting (as we'll explore later) relies on variations starting from winter averages, characterized by very high backscatter.  We aim to identify differences in backscatter between the winter and non-winter periods: while ice typically exhibits high backscatter, areas experiencing water melt show lower backscatter readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082f390-3f3e-4c66-b8d8-072e37612d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018\n",
    "start_date = np.datetime64(\"2018-06-01\")\n",
    "end_date = np.datetime64(\"2018-08-31\")\n",
    "indices_2018 = find_indices_between_dates(dates, start_date, end_date)\n",
    "winter_2018 = stack_ascat[indices_2018]\n",
    "\n",
    "# 2019\n",
    "start_date = np.datetime64(\"2019-06-01\")\n",
    "end_date = np.datetime64(\"2019-08-31\")\n",
    "indices_2019 = find_indices_between_dates(dates, start_date, end_date)\n",
    "winter_2019 = stack_ascat[indices_2019]\n",
    "\n",
    "# 2020\n",
    "start_date = np.datetime64(\"2020-06-01\")\n",
    "end_date = np.datetime64(\"2020-08-31\")\n",
    "indices_2020 = find_indices_between_dates(dates, start_date, end_date)\n",
    "winter_2020 = stack_ascat[indices_2020]\n",
    "\n",
    "# Winter's mean\n",
    "mean_winter_2018 = np.nanmean(winter_2018, axis=0)\n",
    "mean_winter_2019 = np.nanmean(winter_2019, axis=0)\n",
    "mean_winter_2020 = np.nanmean(winter_2020, axis=0)\n",
    "\n",
    "# Plot the georeferenced winter's mean\n",
    "plt.figure(figsize=(12, 2))\n",
    "\n",
    "# Plot mean_stack_1819\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(mean_winter_2018,  cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=1)\n",
    "plt.title(\"Winter 2018\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)  # Adjust colorbar font size\n",
    "\n",
    "# Plot mean_stack_1920\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mean_winter_2019,  cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=1)\n",
    "plt.title(\"Winter 2019\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)  # Adjust colorbar font size\n",
    "\n",
    "# Plot mean_stack_2021\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(mean_winter_2020,  cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=1)\n",
    "plt.title(\"Winter 2020\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)  # Adjust colorbar font size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b63cf9-fe65-4080-8077-9162ca58e386",
   "metadata": {},
   "source": [
    "# <font color='red'> Comparision for the year 2019: winter mean vs yearly mean </font> \n",
    "This is a comparison for the year 2019 on a large temporal scale, aimed at visualizing the macro areas where melt zones are concentrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66fc24d-d6ae-480b-8483-5438ad1ff9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the georeferenced winter's mean\n",
    "plt.figure(figsize=(12, 2))\n",
    "\n",
    "# Plot mean_stack_1819\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(mean_stack_1920,  cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=1)\n",
    "plt.title(\"Mean Stack 2019-2020\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)  # Adjust colorbar font size\n",
    "\n",
    "# Plot winter 2019\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(mean_winter_2019,  cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=1)\n",
    "plt.title(\"Winter 2019\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)  # Adjust colorbar font size\n",
    "\n",
    "# Plot winter minus mean_stack_1920\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(mean_winter_2019 - mean_stack_1920,  cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=0.5012)\n",
    "plt.title(\"Difference winter - yearly 2019\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=8)  # Adjust colorbar font size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb5c08-a5e8-475c-b5b5-36a6293757c1",
   "metadata": {},
   "source": [
    "## Computation of last doy melt \n",
    "\n",
    "To ensure the captured data corresponded to the end of the melt season, the study focuses exclusively on afternoon (6 PM) observations, as morning observations (6 AM) exhibit less melting [Trusel, L. D., et al. (2012). Antarctic surface melting dynamics: Enhanced perspectives from radar scatterometer data. Journal of Geophysical Research: Earth Surface, 117(F2).]. \n",
    "The melt detection algorithm proposed by Ashcraft [Ashcraft, I. S., & Long, D. G. (2006). Comparison of methods for melt detection over Greenland using active and passive microwave measurements. International Journal of Remote Sensing, 27(12), 2469-2488.] is implemented, assuming the presence of melt when the backscatter intensity falls below the annual winter mean by a threshold of 3 dB. Melt periods need to encompass four consecutive observations, with at least three out of the four observations indicating melt. Individual melt days are excluded, as a longer duration of melting is deemed necessary for aquifer formation. The last day of melt within the final selected melt period represents the \"end of the melt season\".\n",
    "\n",
    "We are now going to calculate the last day of melt up to June 30th of each year. Specifically, we are interested in identifying the final day of melt during the first half of the year. We won't include late melt days in this analysis. \"Late melt\" in Antarctica typically refers to the period of time during the austral summer (December to February) when surface melting of ice and snow occurs later than usual. This phenomenon can have various causes, including weather patterns, atmospheric conditions, and changes in regional climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2309d0-017e-484e-ad93-cee25f2bdad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019\n",
    "start_date = np.datetime64(\"2019-01-01\")\n",
    "end_date = np.datetime64(\"2019-06-30\")\n",
    "indices_19 = find_indices_between_dates(dates, start_date, end_date)\n",
    "stack19 = stack_ascat[indices_19]\n",
    "dates19 = dates[indices_19[0]:indices_19[len(indices_19)-1]]\n",
    "\n",
    "# 2020\n",
    "start_date = np.datetime64(\"2020-01-01\")\n",
    "end_date = np.datetime64(\"2020-06-30\")\n",
    "indices_20 = find_indices_between_dates(dates, start_date, end_date)\n",
    "stack20 = stack_ascat[indices_20]\n",
    "dates20 = dates[indices_20[0]:indices_20[len(indices_20)-1]]\n",
    "\n",
    "# 2021\n",
    "start_date = np.datetime64(\"2021-01-01\")\n",
    "end_date = np.datetime64(\"2021-06-30\")\n",
    "indices_21 = find_indices_between_dates(dates, start_date, end_date)\n",
    "stack21 = stack_ascat[indices_21]\n",
    "dates21 = dates[indices_21[0]:indices_21[len(indices_21)-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e7e24-07dc-437e-a7fb-410cf41f07f3",
   "metadata": {},
   "source": [
    "# <font color='red'> Application of melt threshold </font> \n",
    "\n",
    "This section involves the implementation of the actual melt algorithm: for each pixel, if the difference of 3 dB between the winter period and the i-th day is exceeded, the pixel is considered to have experienced melt on that day. The comparison is made against the winter average of that pixel.\n",
    "For each image, each pixel is considered melt if:$\\sigma_0 \\leq \\bar{\\sigma}_{\\text{0 winter}} - 3 \\text{db} $, where $\\bar{\\sigma}_{\\text{0 winter}}$ is the winter mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c85a7-4b7b-4520-86af-83a156883c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the year 2019, due to sensor faults, we have significantly fewer images compared to the other two years.\n",
    "# Threshold melt of 3 db between winter average and current image is expressed as float number\n",
    "threshold = 10 ** (-3 * 0.1)\n",
    "\n",
    "# Define the dimensions of the matrices\n",
    "rows, cols = stack19[0].shape  # Assuming images in the stack have the same dimensions\n",
    "\n",
    "# Create containers for matrices\n",
    "melt19 = [np.zeros((rows, cols)) for _ in range(len(stack19))]\n",
    "melt20 = [np.zeros((rows, cols)) for _ in range(len(stack20))]\n",
    "melt21 = [np.zeros((rows, cols)) for _ in range(len(stack21))]\n",
    "\n",
    "# Calculate the differences and assign appropriate values\n",
    "for i in range(len(stack19)):\n",
    "    melt19[i][np.where(mean_winter_2018 - stack19[i] > threshold)] = 1\n",
    "\n",
    "for i in range(len(stack20)):\n",
    "    melt20[i][np.where(mean_winter_2019 - stack20[i] > threshold)] = 1\n",
    "\n",
    "for i in range(len(stack21)):\n",
    "    melt21[i][np.where(mean_winter_2020 - stack21[i] > threshold)] = 1\n",
    "\n",
    "# Sum the images in melt19, melt20, and melt21\n",
    "# Calculate the total number of days with melt.\n",
    "sum_melt19 = np.sum(melt19, axis=0)\n",
    "sum_melt20 = np.sum(melt20, axis=0)\n",
    "sum_melt21 = np.sum(melt21, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3814a-b043-4190-99cf-3ce3cf4515cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times melt up to 30th June (note that we do not have an ascat image per day)\n",
    "# The colorbar has been saturated up to the number of images avaible up to 30th june: it is a relative number whose maximum value coincides with the number of images we have for that particular year. \n",
    "\n",
    "\n",
    "# Mask application\n",
    "sum_melt19_masked = np.ma.masked_where(np.isnan(mask), sum_melt19)\n",
    "sum_melt20_masked = np.ma.masked_where(np.isnan(mask), sum_melt20)\n",
    "sum_melt21_masked = np.ma.masked_where(np.isnan(mask), sum_melt21)\n",
    "\n",
    "# Matrices plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 2))\n",
    "\n",
    "# Plot per sum_melt19\n",
    "img1 = axs[0].imshow(sum_melt19_masked, cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=len(dates19))\n",
    "axs[0].set_title('Number of times melt: 2019')\n",
    "axs[0].set_xlabel('Longitude')\n",
    "axs[0].set_ylabel('Latitude')\n",
    "cbar1 = fig.colorbar(img1, ax=axs[0])\n",
    "cbar1.set_label('N melt days')\n",
    "\n",
    "# Plot per sum_melt20\n",
    "img2 = axs[1].imshow(sum_melt20_masked, cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=len(dates20))\n",
    "axs[1].set_title('Number of times melt: 2020')\n",
    "axs[1].set_xlabel('Longitude')\n",
    "axs[1].set_ylabel('Latitude')\n",
    "cbar2 = fig.colorbar(img2, ax=axs[1])\n",
    "cbar2.set_label('N melt days')\n",
    "\n",
    "# Plot per sum_melt21\n",
    "img3 = axs[2].imshow(sum_melt21_masked, cmap='jet', extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=len(dates21))\n",
    "axs[2].set_title('Number of times melt: 2021')\n",
    "axs[2].set_xlabel('Longitude')\n",
    "axs[2].set_ylabel('Latitude')\n",
    "cbar3 = fig.colorbar(img3, ax=axs[2])\n",
    "cbar3.set_label('N melt days')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154048d-bd8f-40b8-9a1e-fc3189448645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion from date to doy (day of year)\n",
    "\n",
    "import datetime\n",
    "\n",
    "doy19 = [date.timetuple().tm_yday for date in dates19]\n",
    "doy20 = [date.timetuple().tm_yday for date in dates20]\n",
    "doy21 = [date.timetuple().tm_yday for date in dates21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a02c3-caa4-4360-b939-b860e2c51ec7",
   "metadata": {},
   "source": [
    "## Last DoY melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77971f47-f8e9-458d-a4f4-cd1b3f59397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each pixel, it searches for the last positive melt value, and from that index, I derive the last day of the year (DOY).\n",
    "\n",
    "# Calculating the indices of the last occurrence of 1 for each element i, j in the matrices\n",
    "indices_19 = np.zeros_like(melt19[0])\n",
    "indices_20 = np.zeros_like(melt20[0])\n",
    "indices_21 = np.zeros_like(melt21[0])\n",
    "\n",
    "for i in range(melt19[0].shape[0]):\n",
    "    for j in range(melt19[0].shape[1]):\n",
    "        for k in range(len(melt19)):\n",
    "            if melt19[k][i, j] == 1:\n",
    "                indices_19[i, j] = k + 1\n",
    "\n",
    "for i in range(melt20[0].shape[0]):\n",
    "    for j in range(melt20[0].shape[1]):\n",
    "        for k in range(len(melt20)):\n",
    "            if melt20[k][i, j] == 1:\n",
    "                indices_20[i, j] = k + 1\n",
    "\n",
    "for i in range(melt21[0].shape[0]):\n",
    "    for j in range(melt21[0].shape[1]):\n",
    "        for k in range(len(melt21)):\n",
    "            if melt21[k][i, j] == 1:\n",
    "                indices_21[i, j] = k + 1\n",
    "\n",
    "last_doy19 = np.zeros_like(melt19[0])\n",
    "last_doy20 = np.zeros_like(melt20[0])\n",
    "last_doy21 = np.zeros_like(melt21[0])\n",
    "\n",
    "# Last doy melt 2019\n",
    "for i in range(indices_19.shape[0]):\n",
    "    for j in range(indices_19.shape[1]):\n",
    "        if indices_19[i, j] > 0:\n",
    "            ind_int = int(indices_19[i, j] - 1)\n",
    "            last_doy19[i, j] = doy19[ind_int]\n",
    "\n",
    "# Last doy melt 2020\n",
    "for i in range(indices_20.shape[0]):\n",
    "    for j in range(indices_20.shape[1]):\n",
    "        if indices_20[i, j] > 0:\n",
    "            ind_int = int(indices_20[i, j] - 1)\n",
    "            last_doy20[i, j] = doy20[ind_int]\n",
    "\n",
    "\n",
    "# Last doy melt 2021\n",
    "for i in range(indices_21.shape[0]):\n",
    "    for j in range(indices_21.shape[1]):\n",
    "        if indices_21[i, j] > 0:\n",
    "            ind_int = int(indices_21[i, j] - 1)\n",
    "            last_doy21[i, j] = doy21[ind_int]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe006d6-9d03-4d8a-bbec-51860779490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last doy melt: up to 30th June, plot\n",
    "\n",
    "# Saturation value\n",
    "\n",
    "sat = 80\n",
    "style = 'gist_ncar'\n",
    "\n",
    "# Mask application\n",
    "doy_melt19_masked = np.ma.masked_where(np.isnan(mask), last_doy19)\n",
    "doy_melt20_masked = np.ma.masked_where(np.isnan(mask), last_doy20)\n",
    "doy_melt21_masked = np.ma.masked_where(np.isnan(mask), last_doy21)\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 2))\n",
    "\n",
    "# Last doy melt 2019\n",
    "img1 = axs[0].imshow(doy_melt19_masked, cmap=style, extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=sat)\n",
    "axs[0].set_title('Last doy melt: 2019')\n",
    "axs[0].set_xlabel('Longitude')\n",
    "axs[0].set_ylabel('Latitude')\n",
    "cbar1 = fig.colorbar(img1, ax=axs[0])\n",
    "cbar1.set_label('Last DOY melt')\n",
    "\n",
    "# Last doy melt 2020\n",
    "img2 = axs[1].imshow(doy_melt20_masked, cmap=style, extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=sat)\n",
    "axs[1].set_title('Last doy melt: 2020')\n",
    "axs[1].set_xlabel('Longitude')\n",
    "axs[1].set_ylabel('Latitude')\n",
    "cbar2 = fig.colorbar(img2, ax=axs[1])\n",
    "cbar2.set_label('Last DOY melt')\n",
    "\n",
    "# Last doy melt 2021\n",
    "img3 = axs[2].imshow(doy_melt21_masked, cmap=style, extent=(lon.min(), lon.max(), lat.min(), lat.max()), vmin=0, vmax=sat)\n",
    "axs[2].set_title('Last doy melt: 2021')\n",
    "axs[2].set_xlabel('Longitude')\n",
    "axs[2].set_ylabel('Latitude')\n",
    "cbar3 = fig.colorbar(img3, ax=axs[2])\n",
    "cbar3.set_label('Last DOY melt')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb13cef-62c4-4431-9f0a-012384174909",
   "metadata": {},
   "source": [
    "## Import model data \n",
    "\n",
    "A Regional Climate Model (RCM) is a type of atmospheric model designed to simulate climate conditions over a specific region at a certain spatial resolution. RCMs contain mathematical equations that represent physical processes such as radiation, convection, and advection, similar to global climate models but focused on a smaller geographical area.\n",
    "\n",
    "RACMO (Regional Atmospheric Climate Model) is a specific RCM developed by the Royal Netherlands Meteorological Institute (KNMI) primarily to study polar regions, particularly Antarctica and Greenland. RACMO aims to provide detailed information about atmospheric variables such as temperature, precipitation, wind patterns, and humidity over these regions.\n",
    "To create RACMO, scientists collect observational data from various sources such as weather stations, satellites, and field campaigns. This observational data is used to initialize the model and to validate its performance. The model equations are then solved numerically using computer simulations to predict how the climate will evolve over time under different scenarios and forcings.\n",
    "RACMO incorporates processes specific to polar regions, such as ice melt, snow accumulation, and atmospheric circulation patterns, to provide accurate simulations of the climate in these areas. It can be used to study the impacts of climate change on polar ice sheets, sea ice extent, and regional climate variability.\n",
    "\n",
    "in the context of RACMO, melt flux refers to the rate at which snow or ice melts and releases liquid water into the environment. It's measured as the volume of water produced per unit area over a specific time period, such as millimeters per day. Factors like temperature, solar radiation, wind, and topography influence melt flux. Understanding melt flux is crucial for assessing freshwater resources, hydrological cycles, and the impacts of climate change on snow and ice dynamics.\n",
    "\n",
    "We are going to use meltflux data which are statistically downscaled to 2 km  x 2 km from the output of the regional climate model RACMO2.3p2 (27 km x 27 km resolution) in the Antarctic region.\n",
    "[NoÃ«l, B. et al. (2023). Higher Antarctic ice sheet accumulation and surface melt rates revealed at 2 km resolution. Nature communications, 14(1), 7949.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a3e12-ab31-483e-b419-8a3482472a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to use the model data to plot the cumulative melt [mm w.e./y] over the year for each pixel.\n",
    "# Model images parameters\n",
    "\n",
    "# Path to the georeferenced TIFF file\n",
    "file_path = \"Data/ASCAT/Melt_model_2019.tif\"\n",
    "\n",
    "# Open the TIFF file using rasterio\n",
    "with rasterio.open(file_path) as src:\n",
    "    # Display basic information about the file\n",
    "    print(\"Number of bands:\", src.count)\n",
    "    print(\"Matrix dimensions:\", src.shape)\n",
    "    print(\"Spatial reference system:\", src.crs)\n",
    "    print(\"Geographic extent:\", src.bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bab9a23-e5d3-4278-a156-64c71437843f",
   "metadata": {},
   "source": [
    "# <font color='red'> Visual comparision with melt flux  </font> \n",
    "You will see how in 2019, there is less effective functioning due to fewer images available, whereas in other years, there is a good correspondence between areas with high melt rates and areas where the last Day of Year (DoY) melt is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d778aa-3c2f-47de-80ab-7f5eb9104373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparision with melt flux rate estimated by the model: 2019\n",
    "\n",
    "# Note that model's images have a better resolution than ASCAT\n",
    "\n",
    "# Definition of parameters\n",
    "\n",
    "left, bottom, right, top = -2794000.0, 30000.0, -1304000.0, 2508000.0\n",
    "rows, cols = 745, 1239\n",
    "resolution = 2000  # Step\n",
    "\n",
    "# Creation of meshgrid matrices for x and y coordinates\n",
    "x_model = np.linspace(left, right, cols)\n",
    "y_model = np.linspace(bottom, top, rows)\n",
    "xx_model, yy_model = np.meshgrid(x_model, y_model)\n",
    "\n",
    "# Melt flux saturation value\n",
    "sat_model = 600\n",
    "\n",
    "\n",
    "# Open the TIFF file using rasterio\n",
    "file_path = \"Data/ASCAT/Melt_model_2019.tif\"\n",
    "\n",
    "# Plotting the model melt flux for 2019\n",
    "with rasterio.open(file_path) as src:\n",
    "    plt.figure(figsize=(14, 7))  # Adjust figure size as needed\n",
    "    plt.subplot(1, 2, 1)  # First subplot\n",
    "    plt.imshow(src.read(1), cmap=style, extent=(xx_model.min(), xx_model.max(), yy_model.min(), yy_model.max()), vmin=0, vmax=sat_model)\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title('Model Melt Flux: 2019')\n",
    "    plt.colorbar(label='Melt Flux')\n",
    "    plt.grid(visible=True)\n",
    "\n",
    "# Plotting the last day of year (doy) melt for 2019\n",
    "plt.subplot(1, 2, 2)  # Second subplot\n",
    "img2 = plt.imshow(doy_melt19_masked, cmap=style, extent=(xx.min(), xx.max(), yy.min(), yy.max()), vmin=0, vmax=sat)\n",
    "plt.title('Last Day of Year Melt: 2019')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "cbar2 = plt.colorbar(img2)\n",
    "cbar2.set_label('Last DoY melt')\n",
    "plt.grid(visible=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bade315-a020-4030-aab8-81c5d2b80895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparision with melt flux rate estimated by the model: 2020\n",
    "\n",
    "# Note that model's images have a better resolution than ASCAT\n",
    "\n",
    "# Open the TIFF file using rasterio\n",
    "file_path = \"Data/ASCAT/Melt_model_2020.tif\"\n",
    "\n",
    "# Plotting the model melt flux for 2019\n",
    "with rasterio.open(file_path) as src:\n",
    "    plt.figure(figsize=(14, 7))  # Adjust figure size as needed\n",
    "    plt.subplot(1, 2, 1)  # First subplot\n",
    "    plt.imshow(src.read(1), cmap=style, extent=(xx_model.min(), xx_model.max(), yy_model.min(), yy_model.max()), vmin=0, vmax=sat_model)\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title('Model Melt Flux: 2020')\n",
    "    plt.colorbar(label='Melt Flux')\n",
    "    plt.grid(visible=True)\n",
    "\n",
    "# Plotting the last day of year (doy) melt for 2019\n",
    "plt.subplot(1, 2, 2)  # Second subplot\n",
    "img2 = plt.imshow(doy_melt20_masked, cmap=style, extent=(xx.min(), xx.max(), yy.min(), yy.max()), vmin=0, vmax=sat)\n",
    "plt.title('Last Day of Year Melt: 2020')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "cbar2 = plt.colorbar(img2)\n",
    "cbar2.set_label('Last DoY melt')\n",
    "plt.grid(visible=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff945b-e1bf-41ac-8d1e-4db3e44bb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- neat Antarctic melt plotting utilities (Cartopy) ---\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "# Default map projections\n",
    "MAP_PROJ = ccrs.Stereographic(central_longitude=0, central_latitude=-90)\n",
    "PLATE_CARREE = ccrs.PlateCarree()\n",
    "SOUTH_POLAR_STEREO = ccrs.SouthPolarStereo()\n",
    "\n",
    "# Handy named colormaps\n",
    "COLORMAPS = {\n",
    "    \"melt_classic\": \"YlOrRd\",\n",
    "    \"melt_modern\": \"plasma\",\n",
    "    \"ice_blue\": \"Blues\",\n",
    "    \"thermal\": \"hot\",\n",
    "    \"ocean\": \"ocean\",\n",
    "    \"viridis\": \"viridis\",\n",
    "    \"turbo\": \"turbo\",\n",
    "}\n",
    "\n",
    "\n",
    "def create_custom_melt_colormap() -> LinearSegmentedColormap:\n",
    "    \"\"\"Dark blue -> light blue -> yellow -> orange -> red.\"\"\"\n",
    "    colors = [\"#0d47a1\", \"#42a5f5\", \"#81d4fa\", \"#fff176\", \"#ffb74d\", \"#ff7043\", \"#d32f2f\"]\n",
    "    return LinearSegmentedColormap.from_list(\"melt_gradient\", colors, N=256)\n",
    "\n",
    "\n",
    "def _auto_vlims(a: np.ndarray, vmin: Optional[float], vmax: Optional[float]) -> Tuple[float, float]:\n",
    "    \"\"\"Percentile stretch if vmin/vmax not provided.\"\"\"\n",
    "    if vmin is None or vmax is None:\n",
    "        finite = np.asarray(a, dtype=float)\n",
    "        finite = finite[np.isfinite(finite)]\n",
    "        if finite.size == 0:\n",
    "            return 0.0, 1.0\n",
    "        p2, p98 = np.percentile(finite, [2, 98])\n",
    "        vmin = p2 if vmin is None else vmin\n",
    "        vmax = p98 if vmax is None else vmax\n",
    "        if vmin == vmax:\n",
    "            vmax = vmin + 1.0\n",
    "    return float(vmin), float(vmax)\n",
    "\n",
    "\n",
    "def _resolve_cmap(cmap: Union[str, LinearSegmentedColormap]) -> Union[str, LinearSegmentedColormap]:\n",
    "    if isinstance(cmap, str) and cmap in COLORMAPS:\n",
    "        return COLORMAPS[cmap]\n",
    "    return cmap\n",
    "\n",
    "\n",
    "def plot_melt_cartopy(\n",
    "    melt_data: np.ndarray,\n",
    "    *,\n",
    "    # Either lon/lat (in degrees) OR projected x/y (SouthPolarStereo meters)\n",
    "    lon: Optional[np.ndarray] = None,\n",
    "    lat: Optional[np.ndarray] = None,\n",
    "    x: Optional[np.ndarray] = None,\n",
    "    y: Optional[np.ndarray] = None,\n",
    "    title: str = \"Melt Days\",\n",
    "    year: Optional[Union[int, str]] = None,\n",
    "    cmap: Union[str, LinearSegmentedColormap] = \"plasma\",\n",
    "    vmin: Optional[float] = None,\n",
    "    vmax: Optional[float] = None,\n",
    "    mask_zeros: bool = True,\n",
    "    coastline_style: str = \"clean\",  # \"clean\" | \"minimal\" | \"detailed\"\n",
    "    colorbar_label: str = \"Cumulative Melt Days\",\n",
    "    figsize: Tuple[int, int] = (12, 10),\n",
    "    background_face: str = \"#ffffff\",\n",
    ") -> Tuple[plt.Figure, plt.Axes, any]:\n",
    "    \"\"\"\n",
    "    Plot Antarctic melt data in a South Polar projection with a clean aesthetic.\n",
    "\n",
    "    Pass either (lon, lat) in degrees OR (x, y) already in SouthPolarStereo meters.\n",
    "    - If lon/lat are given, the data are assumed on a geographic grid and drawn with PlateCarree().\n",
    "    - If x/y are given, the data are assumed in SouthPolarStereo and drawn in that CRS.\n",
    "\n",
    "    Returns (fig, ax, mappable).\n",
    "    \"\"\"\n",
    "    A = np.asarray(melt_data)\n",
    "    if A.ndim != 2:\n",
    "        raise ValueError(f\"melt_data must be 2D, got shape {A.shape}\")\n",
    "\n",
    "    # Choose data CRS and coordinate arrays\n",
    "    if lon is not None and lat is not None:\n",
    "        data_crs = PLATE_CARREE\n",
    "        X, Y = np.asarray(lon), np.asarray(lat)\n",
    "    elif x is not None and y is not None:\n",
    "        data_crs = SOUTH_POLAR_STEREO\n",
    "        X, Y = np.asarray(x), np.asarray(y)\n",
    "    else:\n",
    "        raise ValueError(\"Provide either (lon, lat) OR (x, y) coordinates.\")\n",
    "\n",
    "    # Mask zeros if desired (helps avoid background color influence)\n",
    "    if mask_zeros:\n",
    "        A = np.ma.masked_where(A == 0, A)\n",
    "\n",
    "    vmin, vmax = _auto_vlims(A, vmin, vmax)\n",
    "    cmap = _resolve_cmap(cmap)\n",
    "\n",
    "    # Prepare coordinates for pcolormesh: accept 1D or 2D\n",
    "    if X.ndim == 1 and Y.ndim == 1:\n",
    "        # Expect len(X) == A.shape[1] and len(Y) == A.shape[0]\n",
    "        if len(X) != A.shape[1] or len(Y) != A.shape[0]:\n",
    "            raise ValueError(\n",
    "                f\"When X/Y are 1D, lengths must match data shape (Y: {len(Y)} vs {A.shape[0]}, X: {len(X)} vs {A.shape[1]}).\"\n",
    "            )\n",
    "        XX, YY = np.meshgrid(X, Y)\n",
    "    elif X.ndim == 2 and Y.ndim == 2:\n",
    "        XX, YY = X, Y\n",
    "        if XX.shape != A.shape or YY.shape != A.shape:\n",
    "            raise ValueError(f\"2D X/Y must match data shape: X {XX.shape}, Y {YY.shape}, A {A.shape}.\")\n",
    "    else:\n",
    "        raise ValueError(\"X and Y must be both 1D or both 2D, with consistent shapes.\")\n",
    "\n",
    "    # Figure & axis\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize, subplot_kw={\"projection\": MAP_PROJ})\n",
    "    fig.patch.set_facecolor(background_face)\n",
    "    ax.set_facecolor(\"#f8f9fa\")  # soft gray to avoid color clashes\n",
    "\n",
    "    # Draw data (pcolormesh is robust for geolocated grids)\n",
    "    m = ax.pcolormesh(XX, YY, A, transform=data_crs, shading=\"auto\", cmap=cmap, vmin=vmin, vmax=vmax, zorder=2)\n",
    "\n",
    "    # Coastlines / features\n",
    "    if coastline_style == \"clean\":\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=1.2, edgecolor=\"white\", facecolor=\"none\", zorder=3)\n",
    "    elif coastline_style == \"minimal\":\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=0.8, edgecolor=\"lightgray\", facecolor=\"none\", zorder=3)\n",
    "    elif coastline_style == \"detailed\":\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=1.6, edgecolor=\"white\", facecolor=\"none\", zorder=3)\n",
    "        # Optional: try ice shelves if Natural Earth data available\n",
    "        try:\n",
    "            ice_shelves = cfeature.NaturalEarthFeature(\n",
    "                \"physical\", \"antarctic_ice_shelves_polys\", \"50m\", facecolor=\"none\", edgecolor=\"lightgray\", linewidth=1.0\n",
    "            )\n",
    "            ax.add_feature(ice_shelves, zorder=3)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Subtle graticule lines (labels on polar projections can be messy, so keep unlabeled)\n",
    "    gl = ax.gridlines(crs=PLATE_CARREE, draw_labels=False, linewidth=0.5, linestyle=\":\", color=\"gray\", alpha=0.4)\n",
    "    ax.set_extent([-180, 180, -90, -55], crs=PLATE_CARREE)  # crop to Antarctica+Southern Ocean rim\n",
    "\n",
    "    # Title\n",
    "    t = f\"{title}\" if year is None else f\"{title} {year}\"\n",
    "    ax.set_title(t, fontsize=16, pad=18, fontweight=\"bold\", color=\"#2c3e50\")\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(m, ax=ax, orientation=\"horizontal\", pad=0.06, shrink=0.78, aspect=40)\n",
    "    cbar.ax.tick_params(labelsize=11)\n",
    "    if colorbar_label:\n",
    "        cbar.set_label(colorbar_label, fontsize=12, fontweight=\"bold\", color=\"#2c3e50\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax, m\n",
    "\n",
    "\n",
    "def print_data_statistics(data: np.ndarray, name: str = \"Dataset\") -> None:\n",
    "    \"\"\"Quick stats for sanity checks.\"\"\"\n",
    "    a = np.asarray(data)\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"{name} Statistics\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Shape: {a.shape}\")\n",
    "    print(f\"Dtype: {a.dtype}\")\n",
    "    print(f\"Total pixels: {a.size:,}\")\n",
    "    nz = int(np.count_nonzero(a))\n",
    "    print(f\"Non-zero pixels: {nz:,}\")\n",
    "    print(f\"Zero pixels: {a.size - nz:,}\")\n",
    "    finite = a[np.isfinite(a)]\n",
    "    if finite.size:\n",
    "        print(f\"Min: {np.nanmin(finite):.2f}\")\n",
    "        print(f\"Max: {np.nanmax(finite):.2f}\")\n",
    "        print(f\"Mean: {np.nanmean(finite):.2f}\")\n",
    "        print(f\"Median: {np.nanmedian(finite):.2f}\")\n",
    "        print(f\"Std: {np.nanstd(finite):.2f}\")\n",
    "    else:\n",
    "        print(\"All values are non-finite.\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "\n",
    "# Backwards-compatible alias if you prefer the old name\n",
    "plot_melt_data = plot_melt_cartopy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
